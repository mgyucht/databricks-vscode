# WARNING THIS FILE IS AUTOGENERATED
#
# Databricks CLI
# Copyright 2017 Databricks, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License"), except
# that the use of services to which certain application programming
# interfaces (each, an "API") connect requires that the user first obtain
# a license for the use of the APIs from Databricks, Inc. ("Databricks"),
# by creating an account at www.databricks.com and agreeing to either (a)
# the Community Edition Terms of Service, (b) the Databricks Terms of
# Service, or (c) another written agreement between Licensee and Databricks
# for the use of the APIs.
#
# You may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
import os
import re

from six.moves.urllib.parse import urlparse


{% set service = services['jobs.JobsService'] %}
{% include "_service_jobs.py.jinja2" %}

{% set service = services['cluster.ClusterService'] %}
{% include "_service_generic.py.jinja2" %}

{% set service = services['cluster.PolicyService'] %}
{% include "_service_generic.py.jinja2" %}

{% set service = services['managedLibraries.ManagedLibraryService'] %}
{% include "_service_generic.py.jinja2" %}

{% set service = services['dbfs.DbfsService'] %}
{% include "_service_dbfs.py.jinja2" %}

{% set service = services['workspace.WorkspaceService'] %}
{% include "_service_generic.py.jinja2" %}

{% set service = services['secret.SecretService'] %}
{% include "_service_generic.py.jinja2" %}

{% set service = services['acl.GroupsService'] %}
{% include "_service_generic.py.jinja2" %}

{% set service = services['token.TokenService'] %}
{% include "_service_generic.py.jinja2" %}

{% set service = services['cluster.InstancePoolService'] %}
{% include "_service_generic.py.jinja2" %}

class DeltaPipelinesService(object):
    def __init__(self, client):
        self.client = client

    def create(
        self,
        id=None,
        name=None,
        storage=None,
        configuration=None,
        clusters=None,
        libraries=None,
        trigger=None,
        filters=None,
        target=None,
        continuous=None,
        development=None,
        allow_duplicate_names=None,
        headers=None,
    ):
        _data = {}
        if id is not None:
            _data['id'] = id
        if name is not None:
            _data['name'] = name
        if storage is not None:
            _data['storage'] = storage
        if configuration is not None:
            _data['configuration'] = configuration
        if clusters is not None:
            _data['clusters'] = clusters
        if libraries is not None:
            _data['libraries'] = libraries
        if trigger is not None:
            _data['trigger'] = trigger
            if not isinstance(trigger, dict):
                raise TypeError('Expected databricks.PipelineTrigger() or dict for field trigger')
        if filters is not None:
            _data['filters'] = filters
            if not isinstance(filters, dict):
                raise TypeError('Expected databricks.Filters() or dict for field filters')
        if target is not None:
            _data['target'] = target
        if continuous is not None:
            _data['continuous'] = continuous
        if development is not None:
            _data['development'] = development
        if allow_duplicate_names is not None:
            _data['allow_duplicate_names'] = allow_duplicate_names
        return self.client.perform_query('POST', '/pipelines', data=_data, headers=headers)

    def deploy(
        self,
        pipeline_id=None,
        id=None,
        name=None,
        storage=None,
        configuration=None,
        clusters=None,
        libraries=None,
        trigger=None,
        filters=None,
        target=None,
        continuous=None,
        development=None,
        allow_duplicate_names=None,
        headers=None,
    ):
        _data = {}
        if id is not None:
            _data['id'] = id
        if name is not None:
            _data['name'] = name
        if storage is not None:
            _data['storage'] = storage
        if configuration is not None:
            _data['configuration'] = configuration
        if clusters is not None:
            _data['clusters'] = clusters
        if libraries is not None:
            _data['libraries'] = libraries
        if trigger is not None:
            _data['trigger'] = trigger
            if not isinstance(trigger, dict):
                raise TypeError('Expected databricks.PipelineTrigger() or dict for field trigger')
        if filters is not None:
            _data['filters'] = filters
            if not isinstance(filters, dict):
                raise TypeError('Expected databricks.Filters() or dict for field filters')
        if target is not None:
            _data['target'] = target
        if continuous is not None:
            _data['continuous'] = continuous
        if development is not None:
            _data['development'] = development
        if allow_duplicate_names is not None:
            _data['allow_duplicate_names'] = allow_duplicate_names
        return self.client.perform_query(
            'PUT',
            '/pipelines/{pipeline_id}'.format(pipeline_id=pipeline_id),
            data=_data,
            headers=headers,
        )

    def delete(self, pipeline_id=None, headers=None):
        _data = {}

        return self.client.perform_query(
            'DELETE',
            '/pipelines/{pipeline_id}'.format(pipeline_id=pipeline_id),
            data=_data,
            headers=headers,
        )

    def get(self, pipeline_id=None, headers=None):
        _data = {}

        return self.client.perform_query(
            'GET',
            '/pipelines/{pipeline_id}'.format(pipeline_id=pipeline_id),
            data=_data,
            headers=headers,
        )

    def list(self, pagination=None, headers=None):
        _data = {}
        if pagination is not None:
            _data['pagination'] = pagination
            if not isinstance(pagination, dict):
                raise TypeError('Expected databricks.Pagination() or dict for field pagination')
        return self.client.perform_query('GET', '/pipelines', data=_data, headers=headers)

    def reset(self, pipeline_id=None, headers=None):
        _data = {}

        return self.client.perform_query(
            'POST',
            '/pipelines/{pipeline_id}/reset'.format(pipeline_id=pipeline_id),
            data=_data,
            headers=headers,
        )

    def run(self, pipeline_id=None, headers=None):
        _data = {}

        return self.client.perform_query(
            'POST',
            '/pipelines/{pipeline_id}/run'.format(pipeline_id=pipeline_id),
            data=_data,
            headers=headers,
        )

    def start_update(self, pipeline_id=None, full_refresh=None, headers=None):
        _data = {}
        if full_refresh:
            _data['full_refresh'] = full_refresh
        _data['cause'] = 'USER_ACTION'
        return self.client.perform_query(
            'POST',
            '/pipelines/{pipeline_id}/start'.format(pipeline_id=pipeline_id),
            data=_data,
            headers=headers,
        )

    def stop(self, pipeline_id=None, headers=None):
        _data = {}

        return self.client.perform_query(
            'POST',
            '/pipelines/{pipeline_id}/stop'.format(pipeline_id=pipeline_id),
            data=_data,
            headers=headers,
        )


class ReposService(object):
    __git_providers__ = {
        "github.com": "gitHub",
        "dev.azure.com": "azureDevOpsServices",
        "gitlab.com": "gitLab",
        "bitbucket.org": "bitbucketCloud",
    }
    __aws_code_commit_regexp__ = re.compile(r"^git-codecommit\.[^.]+\.amazonaws.com$")

    def __init__(self, client):
        self.client = client

    @staticmethod
    def detect_repo_provider(url):
        provider = None
        try:
            netloc = urlparse(url).netloc
            idx = netloc.rfind("@")
            if idx != -1:
                netloc = netloc[(idx + 1) :]
            provider = ReposService.__git_providers__.get(netloc.lower())
            if provider is None and ReposService.__aws_code_commit_regexp__.match(netloc):
                provider = "awsCodeCommit"
        except:
            pass
        return provider

    def list_repos(self, path_prefix=None, next_page_token=None, headers=None):
        _data = {}
        if path_prefix is not None:
            _data['path_prefix'] = path_prefix
        if next_page_token is not None:
            _data['next_page_token'] = next_page_token
        return self.client.perform_query('GET', '/repos', data=_data, headers=headers)

    def get_repo(self, id, headers=None):
        _data = {}

        return self.client.perform_query(
            'GET', '/repos/{id}'.format(id=id), data=_data, headers=headers
        )

    def update_repo(self, id, branch=None, tag=None, headers=None):
        _data = {}
        if branch is not None:
            _data['branch'] = branch
        if tag is not None:
            _data['tag'] = tag
        return self.client.perform_query(
            'PATCH', '/repos/{id}'.format(id=id), data=_data, headers=headers
        )

    def create_repo(self, url, provider, path=None, headers=None):
        _data = {}
        if url is not None:
            _data['url'] = url
        if provider is None or provider.strip() == "":
            provider = self.detect_repo_provider(url)
        if provider is not None:
            _data['provider'] = provider
        else:
            raise ValueError(
                "The Git provider parameter wasn't specified and we can't detect it "
                "from URL. Please pass 'provider' option"
            )
        if path is not None:
            _data['path'] = path
        return self.client.perform_query('POST', '/repos', data=_data, headers=headers)

    def delete_repo(self, id, headers=None):
        _data = {}

        return self.client.perform_query(
            'DELETE', '/repos/{id}'.format(id=id), data=_data, headers=headers
        )
